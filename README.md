# 📖 프로젝트명 

### ✔️ 가족 유대감 형성을 위한 메타버스 라이프로깅 SNS '우리가족섬'
(메타버스 아카데미 2기 최종 프로젝트 기획 / AI / 서버 / 유니티 / 3D모델링 융합 팀 프로젝트)

![image](https://github.com/WooriIsland/AI/assets/115389344/ced0ff5b-e4d2-45b0-96b0-221acab0e8a7)

# 📃 프로젝트 소개

### ✔️ LLaVA v1.5 (13B)/GPT-4-Vision/Langchain을 활용한 AI 앨범과 OpenChat/GPT-4-1106-Preview/Langchain/LLamaIndex를 활용한 AI 챗봇이 결합된 Unity 3D 엔진 기반의 메타버스 라이프로깅 SNS '우리가족섬' 프로젝트입니다.

#### 🔹 사이좋은 가족을 위한 메타버스 라이프로깅 SNS

![image](https://github.com/WooriIsland/AI/assets/115389344/09741836-648a-40c6-88e3-87f433afe76f)

우리가족섬은 가족 구성원의 위치와 일정을 공유하고 함께한 추억들을 기록하는 메타버스 SNS입니다. 우리의 목표는 일상을 공유하여 가족 간의 유대감 형성을 돕고 가족 간의 소통이 더욱 즐거워지도록 돕는 것입니다.

#### 🔹 가족들의 하루를 얼마나 알고 있나요?<br>
 한 집에 살지만, 종일 각자의 일에 바빠 서로에게 관심 가질 시간이 없지는 않나요? 서로를 향한 이해과 애정은 사소한 관심으로부터 시작됩니다. 우리가족섬과 함께 시작해 보세요.

#### 🔹 독립했더라도 가족이니까<br><br>

![image](https://github.com/WooriIsland/AI/assets/115389344/5c0d78ed-3356-4140-8842-217c56532aa8)

대한민국 전체 가구 수 중 1인 가구는 34.6%이고, 이 중 1/3을 차지하는 20-30 대 1인 가구 비율은 20년간 두 배로 증가했습니다. 이렇게 자녀의 독립이나 유학 등으로 기존 가족 단위가 해체되는 경우가 증가하는 요즘, 시공간을 초월해 가족 간의 유대감을 이어나가도록 해 주는  메타버스 공간에서의 만남은 더욱 큰 수요를 가질 것으로 예상됩니다.

#### 🔹 더 가까워지는 우리 가족<br><br>
 '우리가족섬'은 메타버스 환경에서의 상호작용 경험을 바탕으로  가족 간의 관계 개선을 일차적인 목적으로 합니다. 함께 가상 공간에서 시간을 보내고 우리 가족만의 아지트를 채워 나가는 경험은 공동체의식 함양과 건강한 가족 문화 형성에 기여합니다

#### 🔹 자랑하고 싶은 우리 가족<br><br>

![image](https://github.com/WooriIsland/AI/assets/115389344/c792836f-5191-4e10-9d73-31b5a837740c)

 아름답게 꾸민 우리가족섬은 가족이 아닌 사람들에게도 공유하고 자랑할 수 있습니다. 라이프로깅 SNS 서비스로서, 잘 꾸민 가족섬은 우리 가족이 얼마나 친하고 행복한지를 시각적으로 보여줄 수 있는 멋진 방법입니다. 이미 우리에게 익숙한 싸이월드 미니홈피나 인스타 피드와 같은 SNS 공간이지만, 텍스트도 이미지도 영상도 아닌 메타버스 공간, 즉 궁극적 상호 경험 플랫폼의 형태라는 점에서 특별하죠.

 멋진 추억들을 우리만의 공간에 차곡차곡 모아두면, 우리 가족이 이렇게나 행복하다는 사실을 다른 사람들에게도 자랑할 수 있는 근사한 결과물이 되어드립니다. 우리가족섬에 친척과 지인들을 초대해 보세요. 멀리 살아서 자주 뵙지 못하는 할머니부터 예쁘게 꾸민 가족섬 구경하기를 좋아하는 다른 유저들까지, 원하는 모두에게 우리 가족의 즐거운 모습을 자랑할 수 있습니다. 물론, 사생활 보호를 원하는 유저들의 경우에는 섬을 비공개 모드로 전환해 게스트 출입을 막을 수 있습니다.

[지난해 ‘1인 가구’ 비율 처음으로 40% 넘어서, 김원진, 2023.08.23](https://m.khan.co.kr/national/national-general/article/202208231228001#c2b)<br>
[1인 가구 750만명…생활 모습은 '천차만별', 유정무, 2023.08.29](https://www.banronbodo.com/news/articleView.html?idxno=21984)<br>

# 👩‍🔧 팀원 소개 및 역할

### ✔️ 팀원 및 분장
- 메타버스 아카데미 2기 기획 / AI / 서버 / 유니티 / 3D모델링 총 7명
- 팀명 : 팀 까망이
  
🔹 기획<br>
이시온 : 기획 / 디자인

🔹 AI<br>
임정민 : AI 사진 앨범 (인물 안면 인식 / 배경 및 물체 Tagging / 사진 메모 생성)<br>
이승현 : AI 챗봇 (일상 대화 참여 / 축제 정보 조회 / 일정 관리)

🔹 서버<br>
김진우 : 회원가입 / 로그인 / 회원 및 섬 정보 저장  

🔹 유니티<br>
이현숙 : 사진 앨범 UI / GPS 위치 등록 / 캐릭터 상호작용<br>
변지환 : 채팅창 UI / 섬 꾸미기 / 로비 및 방(섬) 생성

🔹 3D 모델링<br>
오유림 : 캐릭터 및 맵 모델링

### ✔️ AI 세부 역할 분담

🔸 임정민
1) CNN 기반의 Face Recognition 모델 활용 개별 안면 데이터 저장 및 사진 속 인물 추출
2) LLaVA v1.5 / GPT-4-Vision 활용 사진 속 배경/물체 추출
3) LLaVA v1.5 / GPT-4-Vision 활용, 사진의 날짜/시간 메타데이터, 인물 , 배경/물체 정보를 토대로 사진별 요약(메모) 생성
4) MySQL , S3 활용 사진 앨범 DB 구축

🔸 이승현
1) OpenChat / Zephyr / GPT-4-1101-Preview 기반 채팅방 AI 챗봇 구현
2) 채팅방에서 이루어지는 대화에 참여하고 인근 축제 및 행사 정보를 추천(크롤링)
3) LLamaIndex, ChromaDB를 활용하여 대화 내역을 저장, 일정 등록 및 조회

# 📅프로젝트 진행 기록

### ✔️ 수행 기간
- 2023.10.04 ~ 2023.12.12

### ✔️ AI 세부 진행 기록

[전체 세부 일정 WBS](https://docs.google.com/spreadsheets/d/12BTyTzNEC8ACqqFglZwhzQND0cvLr3vc/edit?usp=sharing&ouid=117553260777392591903&rtpof=true&sd=true)

🔹 프로토 버전
- 23-10-13 ~ 23-10-14 : 안면 인식 모델 리서치 (임정민) 
- 23-10-14 ~ 23-10-15 : 안면 인식 모델 구현 및 서빙 (임정민)
- 23-10-15 ~ 23-10-15 : 이미지 메타데이터 추출 (임정민) 
- 23-10-15 ~ 23-10-16 : LVM 모델 리서치 (임정민) 
- 23-10-16 ~ 23-10-17 : 채팅 일정 등록 API 구현 (이승현) 
- 23-10-17 ~ 23-10-18 : LVM 모델 구현 및 서빙 (임정민)
- 23-10-18 ~ 23-10-20 : 채팅 일정 수정 API 구현 (이승현) 
- 23-10-19 ~ 23-10-21 : 가족 앨범 모듈 통합 (임정민)
- 23-10-21 ~ 23-10-21 : 채팅 일정 삭제 API / 일정 알림 구현 (이승현)
- 23-10-21 ~ 23-10-24 : 서버 구현 및 Unity 통신 준비 (임정민)
- 23-10-24 ~ 23-10-24 : AI <-> Unity 통신 구현 (이승현)  
- 23-10-24 ~ 23-10-26 : 지역 축제 API 구현 (이승현)
- 23-10-25 ~ 23-10-26 : AI <-> Unity 통신 구현 (임정민) 
- 23-10-26 ~ 23-10-29 : 코드 리팩토링 및 QA (임정민)

🔹 알파 버전
- 23-10-30 ~ 23-11-01 : 가족 앨범 서버 MySQL 연동 (임정민) 
- 23-11-01 ~ 23-11-02 : 가족 앨범 서버 S3 연동 (임정민)
- 23-11-03 ~ 23-11-04 : 가족 구성원 안면 데이터 통신 (임정민)
- 23-11-03 ~ 23-11-06 : 챗봇 LLM 모델 교체 (이승현) 
- 23-11-05 ~ 23-11-06 : 가족 사진 검색/수정/삭제 통신 (임정민)
- 23-11-06 ~ 23-11-07 : 챗봇 구현 방식을 Agent로 변경 (이승현) 
- 23-11-07 ~ 23-11-08 : 사진 요약 LLaVA 모델 성능 고도화 (임정민)
- 23-11-07 ~ 23-11-09 : 챗봇 지연 시간 확인 및 개선 (이승현)
- 23-11-08 ~ 23-11-08 : 지역 축제 자체 DB 구축 (이승현)
- 23-11-08 ~ 23-11-09 : 지역 축제 추천 기능 추가 (이승현) 
- 23-11-09 ~ 23-11-10 : 가족 사진 테스트 데이터 구축 (임정민) 
- 23-11-11 ~ 23-11-13 : 알파 발표 및 시연 준비 (임정민)

🔹 베타 버전
- 23-11-15 ~ 23-11-26 : 챗봇 지연 시간 개선, 정확도 개선 (이승현) 
- 23-11-16 ~ 23-11-17 : 사용자별 안면 데이터 등록 판별 (임정민) 
- 23-11-17 ~ 23-11-17 : AI 앨범 메모 스타일 가이드 검토 (임정민)
- 23-11-17 ~ 23-11-17 : 베타 시연용 단독 인물사진 구축 및 테스트 (임정민)
- 23-11-18 ~ 23-11-18 : 베타 시연 테스트 및 시연 시나리오 PPT(1) (임정민)
- 23-11-20 ~ 23-11-20 : 챗봇 DB 스키마 설계 (이승현)
- 23-11-20 ~ 23-11-21 : 각 섬 아이디 별 채팅 내역 분리 (이승현) 
- 23-11-20 ~ 23-11-22 : 메모 스타일 가이드 기반 모델 고도화 (임정민)
- 23-11-21 ~ 23-11-22 : 채팅 저장, 조회 기능 구현 (이승현) 
- 23-11-23 ~ 23-11-23 : 베타 시연 테스트 및 시연 시나리오 PPT(2) (임정민) 
- 23-11-23 ~ 23-11-23 : 이미지 촬영 위치 메타데이터 번역 수정 (임정민)
- 23-11-24 ~ 23-11-24 : LLaVA vs GPT-4-Vision 지표 비교 (임정민)
- 23-11-24 ~ 23-11-24 : 발표장 공유기 세팅 (임정민)
- 23-11-25 ~ 23-11-27 : 베타 발표 PPT 및 AI 앨범 시연 준비 (임정민)

🔹 최종 버전
- 23-12-02 ~ 23-12-02 : 융합구조도 작성 (임정민) (이승현)
- 23-12-02 ~ 23-12-03 : 테스트 유저 섭외, 촬영 일정 조율 (임정민)
- 23-12-03 ~ 23-12-04 : 인터뷰 및 촬영 (임정민)
- 23-12-05 ~ 23-12-05 : LLaVA vs GPT-4-Vision 추론 속도 측정 (임정민)
- 23-12-06 ~ 23-12-10 : 기술 질문 준비 (임정민)
- 23-12-10 ~ 23-12-11 : 발표 리허설 (임정민)
- 23-12-11 ~ 23-12-11 : 최종 발표 (임정민)

# 💡 주요 내용

### ✔️ LLaVA 1.5v (13B)/ GPT-4-Vision / Langchain을 활용한 AI 앨범

![image](https://github.com/WooriIsland/AI/assets/115389344/5d57f7fd-0c57-4221-bbed-8adf25f9bd49)

##### 1) 전체 원리

![image](https://github.com/WooriIsland/AI/assets/115389344/d2bac5b6-5a59-42c6-aaec-70d3dc829707)

- 앨범에 등록한 사진별 날짜/시간, 위도/경도 메타데이터 추출
- 등록한 안면 데이터 기반 사진 속 인물 추출 
- 사진에 나타나는 배경 및 물체 (장소, 날씨, 가구, 의상 등) 정보 Tagging
- 사진 속 정보(메타데이터, 인물, Tagging)를 종합하여 한 문장의 요약 생성

##### 2) 이미지 날짜/시간, 위도/경도 메타데이터 추출

![image](https://github.com/WooriIsland/AI/assets/115389344/024cfc70-3af5-412a-a026-074a455749a2)

- 등록한 사진의 촬영 날짜/시간 추출
- 위도/경도 메타데이터를 기반으로 위치(주소) 추출

##### 3) 안면 데이터 저장 및 추출

![image](https://github.com/WooriIsland/AI/assets/115389344/69953363-efc0-46ee-a63e-8fb389c50e35)

- 활용 모델 : [Face Recognition](https://github.com/ageitgey/face_recognition)
- 활용 테스트 데이터 : [AI 허브 '가족 관계가 알려진 얼굴 이미지 데이터'](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=528)

- 동일 섬(방)에 소속된 유저별 안면 데이터 등록
- 이후 가족 사진 등록시, 벡터화된 안면 데이터를 기반으로 인물 추출

##### 4) 사진의 배경 및 물체 Tagging 및 요약

🔹 구현 방법 (1)
- 활용 모델 : [LLaVA v1.5 (13B)](https://github.com/haotian-liu/LLaVA)
- 프롬프트
![image](https://github.com/WooriIsland/AI/assets/115389344/9c870e8f-2ec5-4bf8-8951-1a867c9d280e)
- 추론 예시<br>
![image](https://github.com/WooriIsland/AI/assets/115389344/984ec3e6-e009-4134-8634-05aeef44a00c)

🔹 구현 방법 (2)
- 활용 모델 : GPT-4-Vision
- 프롬프트
![image](https://github.com/WooriIsland/AI/assets/115389344/b5c10b73-b0b4-4ada-b90d-42e97508812d)
- 추론 예시<br>
![image](https://github.com/WooriIsland/AI/assets/115389344/b9f6287a-685e-43ed-90d1-77797b4d795f)

🔹 의의
- 배경 및 물체들을 Tagging하여 저장하고, 이를 기반으로 앨범 속 사진들을 검색할 수 있는 기능 지원
- 사진 속 정보(메타데이터, 인물, 배경/물체)들을 토대로 간결한 한 문장으로 요약하여 정리

##### 5) 활용 LVM 모델 비교

![image](https://github.com/WooriIsland/AI/assets/115389344/9059fb6d-c6e5-482d-ae15-f642ddcd26de)

- LLaVA v1.5 (13B)의 경우, RTX4090 24GB 이상 환경에서 추가비용없이 구동 가능
- 하지만 LLaVA는 사진에 대한 사실 자체만을 묘사하는데 그치고, 본 '우리가족섬' 서비스에서 표현하고자 하는 날짜/시간, 인물, 배경 정보를 포함하고 재치있거나 감성적인 형태로 사진을 요약하는데는 한계가 있음
- 또한 적지 않은 확률로 영어로 반환되어 서비스에 적용하기 어려움
- 그리하여 대안으로 GPT-4-Vision을 활용하여 구현함
- GPT-4-Vision의 경우 GPU 요구 사항 없이, 640x640 크기 이미지, 위 프롬프트 기준으로 사진 1장당 약 30원(0.022달러)꼴로 운용 가능함 
- 또한 사진에서 검색 키워드(배경,날씨,물체,장소 등) 추출과 간결하게 재치있는 요약문을 생성하는데 뛰어나 본 서비스에 적용함

# 🛠 기술 스택

### 🔹 언어
<img src="https://img.shields.io/badge/python-3776AB?style=for-the-badge&logo=python&logoColor=white">

### 🔹 주요 라이브러리
<img src="https://img.shields.io/badge/openai-412991?style=for-the-badge&logo=openai&logoColor=white"> <img src="https://img.shields.io/badge/llava-FF2D20?style=for-the-badge&logo=llava&logoColor=white"> <img src="https://img.shields.io/badge/openchat-3B5EE9?style=for-the-badge&logo=openchat&logoColor=white"> <img src="https://img.shields.io/badge/zephyr-31A8FF?style=for-the-badge&logo=zephyr&logoColor=white"> <img src="https://img.shields.io/badge/llamaindex-00CAFF?style=for-the-badge&logo=llamaindex&logoColor=white"> <img src="https://img.shields.io/badge/face recognition-83B81A?style=for-the-badge&logo=face recognition&logoColor=white"> <img src="https://img.shields.io/badge/langchain-EC1C24?style=for-the-badge&logo=langchain&logoColor=white"> <img src="https://img.shields.io/badge/flask-000000?style=for-the-badge&logo=flask&logoColor=white"> <img src="https://img.shields.io/badge/fastapi-009688?style=for-the-badge&logo=fastapi&logoColor=white"> <img src="https://img.shields.io/badge/chromadb-FF0000?style=for-the-badge&logo=chromadb&logoColor=white"> <img src="https://img.shields.io/badge/mysql-4479A1?style=for-the-badge&logo=mysql&logoColor=white"> <img src="https://img.shields.io/badge/amazons3-569A31?style=for-the-badge&logo=amazons3&logoColor=white">

### 🔹 개발 툴
<img src="https://img.shields.io/badge/VS code-2F80ED?style=for-the-badge&logo=VS code&logoColor=white"> <img src="https://img.shields.io/badge/Google Colab-F9AB00?style=for-the-badge&logo=Google Colab&logoColor=white"> 

### 🔹 협업 툴
<img src="https://img.shields.io/badge/Github-181717?style=for-the-badge&logo=Github&logoColor=white"> <img src="https://img.shields.io/badge/Notion-000000?style=for-the-badge&logo=Notion&logoColor=white"> <img src="https://img.shields.io/badge/Figma-F24E1E?style=for-the-badge&logo=Figma&logoColor=white"> 

# 🔍 참고 자료

### ✔️ 시연 영상 / 블로그
- 시연 영상 : [메타버스 아카데미 2기 최종프로젝트 대상 '우리가족섬'](https://youtu.be/vKTtqw60PuQ?si=t9kbl-Yw7uvCULkX)
- Velog : [데스크 워커를 위한 자세 교정 서비스 '척추의 요정' (1)](https://velog.io/@min0731/%EB%8D%B0%EC%8A%A4%ED%81%AC-%EC%9B%8C%EC%BB%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%EC%9E%90%EC%84%B8-%EA%B5%90%EC%A0%95-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%B2%99%EC%B6%94%EC%9D%98-%EC%9A%94%EC%A0%95-1)

### ✔️ 오픈소스 (GitHub)

- https://platform.openai.com/docs/api-reference
- [https://github.com/HW140701/VideoTo3dPoseAndBvh](https://github.com/haotian-liu/LLaVA)
- https://github.com/imoneoi/openchat
- https://github.com/zephyrproject-rtos/zephyr
- https://docs.llamaindex.ai/en/stable/
- https://python.langchain.com/docs/get_started/introduction
- [https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/fine-tuning/gpt-3.5-agent-training/00-fine-tuning.ipynb](https://github.com/ageitgey/face_recognition)
